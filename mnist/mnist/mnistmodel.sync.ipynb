{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc08444",
   "metadata": {},
   "source": [
    "## Download the Mnist dataset as a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12c9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\", train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\", train=False, download=True, transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d624b",
   "metadata": {},
   "source": [
    "## Prepare our data and make it iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db923ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape (NCHW): torch.Size([128, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=128, shuffle=True)\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape (NCHW): {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22431ade",
   "metadata": {},
   "source": [
    "## Making sure we are using the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff76ac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce32fc",
   "metadata": {},
   "source": [
    "## Building and visualizing our CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99375724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_pool_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=3, padding=\"valid\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            nn.Conv2d(1, 1, kernel_size=3, padding=\"valid\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(400, 10),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.conv_pool_relu_stack(x)\n",
    "        # proba = nn.Softmax(1)(logits)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf72373",
   "metadata": {},
   "source": [
    "### Testing without any training our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a0ff2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the logits : torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "proba = model(X)\n",
    "print(f\"Shape of the logits : {proba.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54331d2",
   "metadata": {},
   "source": [
    "### How big is our model and what is it's structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6d81c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: CNN(\n",
      "  (conv_pool_relu_stack): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=400, out_features=10, bias=True)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "We have 4030 trainable parameters in our model\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "nbr_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"We have {nbr_params} trainable parameters in our model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adc5e0",
   "metadata": {},
   "source": [
    "## Optimization hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b44dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700e7ed",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa2774ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        x = X.to(device=device)\n",
    "        y = Y.to(device=device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            x = X.to(device=device)\n",
    "            y = Y.to(device=device)\n",
    "            pred = model(x)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0666ba9",
   "metadata": {},
   "source": [
    "## Actual training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be381d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.296921  [  128/60000]\n",
      "loss: 2.295914  [12928/60000]\n",
      "loss: 2.284094  [25728/60000]\n",
      "loss: 2.264377  [38528/60000]\n",
      "loss: 2.267117  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 27.0%, Avg loss: 2.267086 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.270940  [  128/60000]\n",
      "loss: 2.250805  [12928/60000]\n",
      "loss: 2.248779  [25728/60000]\n",
      "loss: 2.248131  [38528/60000]\n",
      "loss: 2.230788  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 2.208604 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.199913  [  128/60000]\n",
      "loss: 2.173604  [12928/60000]\n",
      "loss: 2.153025  [25728/60000]\n",
      "loss: 2.108766  [38528/60000]\n",
      "loss: 2.043384  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 1.985860 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.983215  [  128/60000]\n",
      "loss: 1.885151  [12928/60000]\n",
      "loss: 1.717968  [25728/60000]\n",
      "loss: 1.517907  [38528/60000]\n",
      "loss: 1.263749  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.150112 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.154312  [  128/60000]\n",
      "loss: 1.130870  [12928/60000]\n",
      "loss: 0.872613  [25728/60000]\n",
      "loss: 0.871329  [38528/60000]\n",
      "loss: 0.737742  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.711541 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.763475  [  128/60000]\n",
      "loss: 0.620567  [12928/60000]\n",
      "loss: 0.644964  [25728/60000]\n",
      "loss: 0.657987  [38528/60000]\n",
      "loss: 0.574034  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.566155 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.570978  [  128/60000]\n",
      "loss: 0.713894  [12928/60000]\n",
      "loss: 0.724515  [25728/60000]\n",
      "loss: 0.632136  [38528/60000]\n",
      "loss: 0.564536  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.507246 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.614654  [  128/60000]\n",
      "loss: 0.538982  [12928/60000]\n",
      "loss: 0.398912  [25728/60000]\n",
      "loss: 0.471668  [38528/60000]\n",
      "loss: 0.659739  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.472301 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.537447  [  128/60000]\n",
      "loss: 0.381105  [12928/60000]\n",
      "loss: 0.566439  [25728/60000]\n",
      "loss: 0.414384  [38528/60000]\n",
      "loss: 0.549298  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.441805 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.480813  [  128/60000]\n",
      "loss: 0.569456  [12928/60000]\n",
      "loss: 0.461517  [25728/60000]\n",
      "loss: 0.408607  [38528/60000]\n",
      "loss: 0.597634  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.427518 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.459787  [  128/60000]\n",
      "loss: 0.398980  [12928/60000]\n",
      "loss: 0.231951  [25728/60000]\n",
      "loss: 0.435155  [38528/60000]\n",
      "loss: 0.390553  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.406923 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.430421  [  128/60000]\n",
      "loss: 0.371651  [12928/60000]\n",
      "loss: 0.279955  [25728/60000]\n",
      "loss: 0.411680  [38528/60000]\n",
      "loss: 0.503739  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.403819 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.522587  [  128/60000]\n",
      "loss: 0.398854  [12928/60000]\n",
      "loss: 0.284848  [25728/60000]\n",
      "loss: 0.438078  [38528/60000]\n",
      "loss: 0.556882  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.395802 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.534312  [  128/60000]\n",
      "loss: 0.402439  [12928/60000]\n",
      "loss: 0.552778  [25728/60000]\n",
      "loss: 0.354402  [38528/60000]\n",
      "loss: 0.371063  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.388267 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.333351  [  128/60000]\n",
      "loss: 0.467783  [12928/60000]\n",
      "loss: 0.383824  [25728/60000]\n",
      "loss: 0.475536  [38528/60000]\n",
      "loss: 0.489245  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.383920 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.268081  [  128/60000]\n",
      "loss: 0.513465  [12928/60000]\n",
      "loss: 0.267238  [25728/60000]\n",
      "loss: 0.484563  [38528/60000]\n",
      "loss: 0.453498  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.378418 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.327143  [  128/60000]\n",
      "loss: 0.363402  [12928/60000]\n",
      "loss: 0.462946  [25728/60000]\n",
      "loss: 0.466526  [38528/60000]\n",
      "loss: 0.338274  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.372820 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.378568  [  128/60000]\n",
      "loss: 0.411246  [12928/60000]\n",
      "loss: 0.473092  [25728/60000]\n",
      "loss: 0.316276  [38528/60000]\n",
      "loss: 0.311822  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.361302 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.365685  [  128/60000]\n",
      "loss: 0.311665  [12928/60000]\n",
      "loss: 0.505455  [25728/60000]\n",
      "loss: 0.354704  [38528/60000]\n",
      "loss: 0.316689  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.361635 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.451658  [  128/60000]\n",
      "loss: 0.364287  [12928/60000]\n",
      "loss: 0.377301  [25728/60000]\n",
      "loss: 0.408160  [38528/60000]\n",
      "loss: 0.398191  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.363284 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.370457  [  128/60000]\n",
      "loss: 0.497736  [12928/60000]\n",
      "loss: 0.522528  [25728/60000]\n",
      "loss: 0.317531  [38528/60000]\n",
      "loss: 0.287042  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.365498 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.587102  [  128/60000]\n",
      "loss: 0.410107  [12928/60000]\n",
      "loss: 0.323112  [25728/60000]\n",
      "loss: 0.435367  [38528/60000]\n",
      "loss: 0.434860  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.346171 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.305688  [  128/60000]\n",
      "loss: 0.377033  [12928/60000]\n",
      "loss: 0.323676  [25728/60000]\n",
      "loss: 0.415093  [38528/60000]\n",
      "loss: 0.403604  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.353919 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.414776  [  128/60000]\n",
      "loss: 0.304525  [12928/60000]\n",
      "loss: 0.497127  [25728/60000]\n",
      "loss: 0.314083  [38528/60000]\n",
      "loss: 0.350929  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.358150 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.459486  [  128/60000]\n",
      "loss: 0.367031  [12928/60000]\n",
      "loss: 0.346639  [25728/60000]\n",
      "loss: 0.425105  [38528/60000]\n",
      "loss: 0.356719  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.348590 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.216148  [  128/60000]\n",
      "loss: 0.292189  [12928/60000]\n",
      "loss: 0.600380  [25728/60000]\n",
      "loss: 0.320592  [38528/60000]\n",
      "loss: 0.233013  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.352888 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.254113  [  128/60000]\n",
      "loss: 0.418955  [12928/60000]\n",
      "loss: 0.382527  [25728/60000]\n",
      "loss: 0.416572  [38528/60000]\n",
      "loss: 0.281172  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.342150 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.343436  [  128/60000]\n",
      "loss: 0.229372  [12928/60000]\n",
      "loss: 0.273855  [25728/60000]\n",
      "loss: 0.438308  [38528/60000]\n",
      "loss: 0.401699  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.335761 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.354079  [  128/60000]\n",
      "loss: 0.463299  [12928/60000]\n",
      "loss: 0.262094  [25728/60000]\n",
      "loss: 0.307311  [38528/60000]\n",
      "loss: 0.547871  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.342877 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.451455  [  128/60000]\n",
      "loss: 0.311200  [12928/60000]\n",
      "loss: 0.461721  [25728/60000]\n",
      "loss: 0.348437  [38528/60000]\n",
      "loss: 0.445812  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.348833 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.252984  [  128/60000]\n",
      "loss: 0.316434  [12928/60000]\n",
      "loss: 0.305713  [25728/60000]\n",
      "loss: 0.277177  [38528/60000]\n",
      "loss: 0.286075  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.331926 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.497725  [  128/60000]\n",
      "loss: 0.441929  [12928/60000]\n",
      "loss: 0.360549  [25728/60000]\n",
      "loss: 0.457494  [38528/60000]\n",
      "loss: 0.345609  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.339800 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.381168  [  128/60000]\n",
      "loss: 0.407149  [12928/60000]\n",
      "loss: 0.255433  [25728/60000]\n",
      "loss: 0.307664  [38528/60000]\n",
      "loss: 0.155600  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.344724 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.493167  [  128/60000]\n",
      "loss: 0.357468  [12928/60000]\n",
      "loss: 0.329783  [25728/60000]\n",
      "loss: 0.433690  [38528/60000]\n",
      "loss: 0.332136  [51328/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.330977 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.292804  [  128/60000]\n",
      "loss: 0.262978  [12928/60000]\n",
      "loss: 0.243052  [25728/60000]\n",
      "loss: 0.240244  [38528/60000]\n",
      "loss: 0.321087  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.341961 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.382099  [  128/60000]\n",
      "loss: 0.241547  [12928/60000]\n",
      "loss: 0.291310  [25728/60000]\n",
      "loss: 0.395815  [38528/60000]\n",
      "loss: 0.389853  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.332512 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.437398  [  128/60000]\n",
      "loss: 0.240502  [12928/60000]\n",
      "loss: 0.314072  [25728/60000]\n",
      "loss: 0.363133  [38528/60000]\n",
      "loss: 0.344354  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.326949 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.441747  [  128/60000]\n",
      "loss: 0.206387  [12928/60000]\n",
      "loss: 0.294218  [25728/60000]\n",
      "loss: 0.349403  [38528/60000]\n",
      "loss: 0.339418  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.335141 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.509493  [  128/60000]\n",
      "loss: 0.211775  [12928/60000]\n",
      "loss: 0.349475  [25728/60000]\n",
      "loss: 0.364284  [38528/60000]\n",
      "loss: 0.328358  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.328265 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.298578  [  128/60000]\n",
      "loss: 0.304887  [12928/60000]\n",
      "loss: 0.364888  [25728/60000]\n",
      "loss: 0.237982  [38528/60000]\n",
      "loss: 0.467914  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.334188 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
